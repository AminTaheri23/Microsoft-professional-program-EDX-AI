# EDX ethics

## 1_1 

ethics is upper than law

sustainability is really imp because we should think before do, we shouldn't clean problems, we should try not tot create one.

data mining is = collect + =Store + process + analyze data revolution is coming. we are optimist. this coming benefit is welcome, bit this have winners and losers. it will benefit all, good and bad. there are some response:

1. stop technological process

2. uncheck optimism

3. uneasy acceptance

4. proactive design

it is our responsibility to identify the harms.

data is facts, data recording is now autonomous, big data is not a good word, because its relative. but we don not need ad technical definition. non digital data records, is not efficient. who or what is recording data.
  ethics: what it means to be ethical person. ethical concern: a concern with human well-being i.e. if you a ethical person, you care about human well-beings ethic is complicated?-lot s of contrast answers are there, the simple one is that its a the value of well being of human. it leave the theories to law experts, we need to understand the values under the theories, they are only 5 values :
  from aspect of others well being:

1. care about other people because they suffer

2. autonomy : controlling them selves.

3. equality 

   

from aspect of my own well being:

1. character excellence

2. trust

   

should I torture sb? no because of these values above. we should appreciate all of above values

### Data ethics

ethics study of human being data ethics= the study of how data affects human well-being data affects human perspective of who will affects

YouTube video: big data gets personal

## 1_2         

law is territorial .law is slower than technology electronic communications privacy act = ecpa = prohibits a third party from intercepting or disclosing communications without authorization law , data analytics and ai

the framework for solving legal problems =issue, rule, Application, Conclusion = IRAC
        teenage girl target pregnancy problem: issue target s rights. rule: privacy right violation,application conclusion it was fine by law but it was not ethical

## 1_3      

lies, truth, statistics numbers lies! easy really easy to misunderstand data 
 collection problem = not being random graph with misleading proportion = visualization problems unit overload= interpretation problem new kind of subjectivity: process with algorithms cleaning data with

 ETL = extraction transformation loading


 hypocritic oath = I swear to do things well tharra are examples of oath, un;s 1985 declarations certified analytics professional code of conduct is another example of  oath modern oath: I, a data practitioner, will promote the well-being of others  and myself while striving to do no harm with data through: 

1. professional application of analytical techniques 

2. humanity in analytics claim

3. anticipation of legal and regulatory scenarios 

4. transparency in computation and documentation 

5. fidelity to this oath beyond the bottom line

## 1_4

irac lab=

Microsoft case =

https://www.fastcompany.com/3067315/data-can-lie-heres-a-guide-to-calling-it-out

machine can decide bias decision like human does because of data and its more dangerous today because of easy tools of big data and its new bullshit

LAB:        

## 2_1 

recidivism = like to commit crime again

conscious bias= you know about it

unconscious bias = u don't know that you have this

ways bias can enter bias:

1. data input biased

2. use of irrelevant data : need a data to run algorithm, machine doesn't use all of variable s (feature selections) . if you tell a machine use zip code, zip code is proxy for race, and make it racist. (feature selection is biased)

 

big data fundamentalisms :

no transparency in data collection and use

who is included and who is excluded

in data revolution, the offline guys will not be considered

based on data we will get special offers,

because of being offline, we are treated differently, because we are excluded from giving data,

 

report of Barak Obama 2016 big data

consumer rights

employee rights

student it rights

criminal justice

best practices of white house to over come bias,

1. challenge related to data inputs used in algorithms: inclusion and exclusion, if you focus on smartphones, your model will be less accurate for poor people with no smartphone this is dissemination

2. the design of algorithm themselves: no transparency in algorithm.

 

11 % of people are credit invisible , they have expired info on their credit. mexican and Latino are more credit invisible.

### ethnicity.

protected characteristics = gander, race, etc.

employment and policy:

employment hiring practices. unknow dat points

### education and policy:

higher education

improving students

learning retention

and graduations

big data in higher education is real!

concern: student antimony, right to identity privacy, we each have a right to create identity.

 

### policing and privacy:

criminal justice and predictive policing , identify crime hotspots

the relationship between computers and community should be healthy,

 

best practices to eliminate bias and prevent discremantion :

1. building systems that support ethics

2. encourage market participant to transparency and accountability and make mechanisms to correct inaccurate data.

3. promote academic research to ensure that people are treated fairly

4. broaden participation in cs and data science for basis fluencies and capabilities.

5. consider the role of government and privet sectors in setting rules of how data is used

### descriptive analytics:

predictive = aggreged data and analytics

descriptive = machine learning (future predictive) (say thing about you that you might not know )        

## 2_2

privacy, privilege's or right :

informational privacy = ssn,race,gender, etc all are our privacy

tort law= protection from harm

privacy law and analytics:

we don't know the answer

publicity and offensive together are dangerous

 

negligence law and analytics:

duty,act reasonable under the circumstances

breach: we breach that duty when not doing reasonable

causation: the link between breach and damages

damages: the harm ie physical, mental and etc.

power imbalances : democracy = demo + kratos = people + power

people have power over government and gov have power have power in business. power != complete control. power = final authorities. knowledge is power = data is power

business have data and have power. power.

## 3_1          ####################

module 3 :

regulation some us and eu law that apply for ai

Update:

Title vii of civil rights act 1964, says that if you are treated differently because of national origin, the employer is acting a discriminations and its prohibited in u.s.

6 month gap for proxy without respect of context is not a good solution.

Marketing at a point of vulnerability to effect more while the vulnerability has been discovered by ai based on your likes on social media

(Further reading)

Calo, Ryan. “Digital Market Manipulation,” The George Washington Law Review, August 2014 Vol. 82 No. 4

De Romree, Henri, Bruce Fecheyr-Lippens, and Bill Schaninger. “People Analytics Reveals Three Things HR May Be Getting Wrong.” http://www.mckinsey.com/business-functions/organization/our-insights/people-analytics-reveals-three-things-hr-may-be-getting-wrong

Gee, Kelsey. “In Unilever's Radical Hiring Experiment, Resumes are Out, Algorithms are In,” Wall Street Journal. https://www.wsj.com/articles/in-unilevers-radical-hiring-experiment-resumes-are-out-algorithms-are-in-1498478400

(/Further reading)

## 3-2

Pupil of eye and concussion with deep learning for sports.

(Further reading)

Bostrom, Nick. Superintelligence: Paths, Dangers, Strategies. Oxford University Press; Oxford, 2014 ed.

Satya Nadella's six design principles for AI: https://www.theverge.com/2016/6/29/12057516/satya-nadella-ai-robot-laws

Information Commissioner's Office. “Big data, artificial intelligence, machine learning and data protection.” https://ico.org.uk/media/for-organisations/documents/2013559/big-data-ai-ml-and-data-protection.pdf

(/Further reading)